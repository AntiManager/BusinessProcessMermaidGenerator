"""
–≠–∫—Å–ø–æ—Ä—Ç –≤ Mermaid —Ñ–æ—Ä–º–∞—Ç (Markdown –∏ HTML) —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏
"""
from typing import Dict, Set, List, Tuple
from pathlib import Path
from models import Operation, Choices, ProcessAnalysis, AnalysisData
from utils import safe_id, escape_text, _escape_multiline, create_markdown_table
from config import ENCODING, STYLES

def build_mermaid_md(
    operations: Dict[str, Operation],
    analysis_data: AnalysisData,
    choices: Choices,
) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç Mermaid –∫–æ–¥ –¥–ª—è Markdown
    """
    external_inputs = analysis_data.external_inputs
    final_outputs = analysis_data.final_outputs
    output_to_operation = analysis_data.output_to_operation
    input_to_operations = analysis_data.input_to_operations
    analysis = analysis_data.analysis
    
    lines = ["```mermaid", "graph LR"]
    for k, v in STYLES.items():
        lines.append(f"    classDef {k} {v};")

    critical_ops = {c.operation for c in analysis.critical_points}

    for inp in sorted(external_inputs):
        if inp:
            lines.append(f'    {safe_id(inp)}(["{escape_text(inp)}"]):::external')
    for out in sorted(final_outputs):
        if out:
            lines.append(f'    {safe_id(out)}(["{escape_text(out)}"]):::final')

    # –ï—Å–ª–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∏–ª–∏ –Ω–µ—Ç —Å—Ç–æ–ª–±—Ü–∞ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
    if choices.no_grouping or not choices.subgroup_column:
        for name in sorted(operations):
            lines.append(_node_line_md(name, operations[name], input_to_operations, critical_ops))
    else:
        from collections import defaultdict
        subgroup_ops = defaultdict(list)
        for name, op in operations.items():
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–æ–¥–≥—Ä—É–ø–ø–æ–π
            if op.subgroup and str(op.subgroup).strip() and str(op.subgroup).strip() != "nan":
                subgroup_ops[op.subgroup].append(name)
            else:
                # –û–ø–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –ø–æ–¥–≥—Ä—É–ø–ø—ã –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                subgroup_ops[None].append(name)

        # –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–≥—Ä—É–ø–ø—ã —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        for subgroup in sorted([sg for sg in subgroup_ops.keys() if sg is not None]):
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É –≥—Ä—É–ø–ø—ã —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–æ–≤
            sg_id = "group_" + safe_id(subgroup)
            lines.append(f'    subgraph {sg_id}["{escape_text(subgroup)}"]')
            for name in sorted(subgroup_ops[subgroup]):
                lines.append(_node_line_md(name, operations[name], input_to_operations, critical_ops))
            lines.append("    end")
        
        # –ó–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –ø–æ–¥–≥—Ä—É–ø–ø—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if None in subgroup_ops and subgroup_ops[None]:
            for name in sorted(subgroup_ops[None]):
                lines.append(_node_line_md(name, operations[name], input_to_operations, critical_ops))

    added = set()
    for name, op in operations.items():
        src_id = safe_id(name)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï –≤—ã—Ö–æ–¥—ã –æ–ø–µ—Ä–∞—Ü–∏–∏
        for output in op.outputs:
            if output and output in final_outputs:
                key = (src_id, output, safe_id(output))
                if key not in added:
                    added.add(key)
                    lines.append(f'    {src_id}-- "{escape_text(output)}" -->{safe_id(output)}')
            
            # –°–≤—è–∑—ã–≤–∞–µ–º –≤—ã—Ö–æ–¥—ã —Å –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏—Ö –∏—Å–ø–æ–ª—å–∑—É—é—Ç
            if output in input_to_operations:
                for target_op in input_to_operations[output]:
                    key = (src_id, output, safe_id(target_op))
                    if key not in added:
                        added.add(key)
                        lines.append(f'    {src_id}-- "{escape_text(output)}" -->{safe_id(target_op)}')
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Ö–æ–¥—ã –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        for inp in op.inputs:
            if not inp:
                continue
            if inp in external_inputs:
                key = (safe_id(inp), inp, src_id)
                if key not in added:
                    added.add(key)
                    lines.append(f'    {safe_id(inp)}-- "{escape_text(inp)}" -->{src_id}')

    lines.append("```")
    return "\n".join(lines)

def _node_line_md(name: str, op: Operation,
               input_to_operations: Dict[str, List[str]],
               critical_ops: Set[str]) -> str:
    node_id = safe_id(name)
    if name in critical_ops:
        style = ":::critical"
    else:
        is_merge = len(op.inputs) > 1
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–≤–µ—Ç–≤–ª–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º –≤—ã—Ö–æ–¥–∞–º
        is_split = any(len(input_to_operations.get(out, [])) > 1 for out in op.outputs)
        style = (
            ":::merge" if is_merge and is_split else
            ":::merge" if is_merge else
            ":::split" if is_split else
            ""
        )
    return f'    {node_id}["{escape_text(op.node_text)}"]{style}'

def build_mermaid_html(
    operations: Dict[str, Operation],
    analysis_data: AnalysisData,
    choices: Choices,
) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Mermaid –∫–æ–¥ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –≤ HTML —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏
    """
    external_inputs = analysis_data.external_inputs
    final_outputs = analysis_data.final_outputs
    output_to_operation = analysis_data.output_to_operation
    input_to_operations = analysis_data.input_to_operations
    analysis = analysis_data.analysis
    
    lines = ["graph LR"]
    for k, v in STYLES.items():
        lines.append(f"    classDef {k} {v};")

    critical_ops = {c.operation for c in analysis.critical_points}

    for inp in sorted(external_inputs):
        if inp:
            lines.append(f'    {safe_id(inp)}(["{escape_text(inp)}"]):::external')
    for out in sorted(final_outputs):
        if out:
            lines.append(f'    {safe_id(out)}(["{escape_text(out)}"]):::final')

    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–ª—è HTML Mermaid
    from collections import defaultdict
    subgroup_ops = defaultdict(list)
    for name, op in operations.items():
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–æ–¥–≥—Ä—É–ø–ø–æ–π
        if op.subgroup and str(op.subgroup).strip() and str(op.subgroup).strip() != "nan":
            subgroup_ops[op.subgroup].append(name)
        else:
            # –û–ø–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –ø–æ–¥–≥—Ä—É–ø–ø—ã –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            subgroup_ops[None].append(name)

    if choices.subgroup_column and not choices.no_grouping:
        # –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–≥—Ä—É–ø–ø—ã —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        for subgroup in sorted([sg for sg in subgroup_ops.keys() if sg is not None]):
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É –≥—Ä—É–ø–ø—ã —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–æ–≤
            sg_id = "group_" + safe_id(subgroup)
            lines.append(f'    subgraph {sg_id}["{escape_text(subgroup)}"]')
            for name in sorted(subgroup_ops[subgroup]):
                lines.append(_node_line_html(name, operations[name], input_to_operations, critical_ops))
            lines.append("    end")
        
        # –ó–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –ø–æ–¥–≥—Ä—É–ø–ø—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if None in subgroup_ops and subgroup_ops[None]:
            for name in sorted(subgroup_ops[None]):
                lines.append(_node_line_html(name, operations[name], input_to_operations, critical_ops))
    else:
        for name in sorted(operations):
            lines.append(_node_line_html(name, operations[name], input_to_operations, critical_ops))

    added = set()
    for name, op in operations.items():
        src_id = safe_id(name)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï –≤—ã—Ö–æ–¥—ã –æ–ø–µ—Ä–∞—Ü–∏–∏
        for output in op.outputs:
            if output and output in final_outputs:
                key = (src_id, output, safe_id(output))
                if key not in added:
                    added.add(key)
                    lines.append(f'    {src_id}-- "{escape_text(output)}" -->{safe_id(output)}')
            
            # –°–≤—è–∑—ã–≤–∞–µ–º –≤—ã—Ö–æ–¥—ã —Å –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏—Ö –∏—Å–ø–æ–ª—å–∑—É—é—Ç
            if output in input_to_operations:
                for target_op in input_to_operations[output]:
                    key = (src_id, output, safe_id(target_op))
                    if key not in added:
                        added.add(key)
                        lines.append(f'    {src_id}-- "{escape_text(output)}" -->{safe_id(target_op)}')
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Ö–æ–¥—ã –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        for inp in op.inputs:
            if not inp:
                continue
            if inp in external_inputs:
                key = (safe_id(inp), inp, src_id)
                if key not in added:
                    added.add(key)
                    lines.append(f'    {safe_id(inp)}-- "{escape_text(inp)}" -->{src_id}')

    return "\n".join(lines)

def _node_line_html(name: str, op: Operation,
                   input_to_operations: Dict[str, List[str]],
                   critical_ops: Set[str]) -> str:
    node_id = safe_id(name)
    if name in critical_ops:
        style = ":::critical"
    else:
        is_merge = len(op.inputs) > 1
        is_split = any(len(input_to_operations.get(out, [])) > 1 for out in op.outputs)
        style = (
            ":::merge" if is_merge and is_split else
            ":::merge" if is_merge else
            ":::split" if is_split else
            ""
        )
    return f'    {node_id}["{escape_text(op.node_text)}"]{style}'

def _build_io_registry(
    external_inputs: Set[str],
    final_outputs: Set[str],
    output_to_operation: Dict[str, str],
    input_to_operations: Dict[str, List[str]],
) -> List[Dict[str, str]]:
    """
    –°—Ç—Ä–æ–∏—Ç —Ä–µ–µ—Å—Ç—Ä –≤—Ö–æ–¥–æ–≤/–≤—ã—Ö–æ–¥–æ–≤
    """
    rows = []
    items = external_inputs | final_outputs | set(output_to_operation) | set(input_to_operations)
    for item in sorted(items):
        if not item:
            continue
        src = "–í–ù–ï–®–ù–ò–ô –í–•–û–î" if item in external_inputs else output_to_operation.get(item, "-")
        tgts = input_to_operations.get(item, [])
        if item in final_outputs and not tgts:
            tgts = ["–ö–û–ù–ï–ß–ù–´–ô –í–´–•–û–î"]
        rows.append({
            "–í—Ö–æ–¥/–í—ã—Ö–æ–¥": item,
            "–ò—Å—Ö–æ–¥–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è": src,
            "–ü–æ—Å–ª–µ–¥—É—é—â–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏": ", ".join(tgts) if tgts else "-",
        })
    return rows

def _build_op_registry(operations: Dict[str, Operation],
                       input_to_operations: Dict[str, List[str]],
                       critical_ops: Set[str]) -> List[Dict[str, str]]:
    """
    –°—Ç—Ä–æ–∏—Ç —Ä–µ–µ—Å—Ç—Ä –æ–ø–µ—Ä–∞—Ü–∏–π
    """
    rows = []
    for name, op in operations.items():
        is_merge = len(op.inputs) > 1
        is_split = any(len(input_to_operations.get(out, [])) > 1 for out in op.outputs)
        node_type = (
            "–°—É–ø–µ—Ä-–∫—Ä–∏—Ç–∏—á–Ω–∞—è" if name in critical_ops else
            "–°–ª–∏—è–Ω–∏–µ+–†–∞–∑–≤–µ—Ç–≤–ª–µ–Ω–∏–µ" if is_merge and is_split else
            "–°–ª–∏—è–Ω–∏–µ" if is_merge else
            "–†–∞–∑–≤–µ—Ç–≤–ª–µ–Ω–∏–µ" if is_split else
            "–û–±—ã—á–Ω—ã–π"
        )
        rows.append({
            "–û–ø–µ—Ä–∞—Ü–∏—è": name,
            "–ì—Ä—É–ø–ø–∞": op.group,
            "–í–ª–∞–¥–µ–ª–µ—Ü": op.owner,
            "–í—Ö–æ–¥—ã": ", ".join(op.inputs) if op.inputs else "-",
            "–í—ã—Ö–æ–¥": ", ".join(op.outputs) if op.outputs else "-",
            "–¢–∏–ø —É–∑–ª–∞": node_type,
            "–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ": op.detailed,
        })
    return rows

def export_mermaid(operations: Dict[str, Operation], analysis_data: AnalysisData, 
                  choices: Choices, available_columns: List[str], output_base: str = None) -> Path:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∏–∞–≥—Ä–∞–º–º—É –≤ Markdown —Å Mermaid - –í–û–ó–í–†–ê–©–ê–ï–¢ Path
    """
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if output_base is None:
        output_base = "business_process_diagram"
    
    output_file = Path(f"{output_base}.md")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Mermaid –∫–æ–¥–∞
    mermaid_code = build_mermaid_md(operations, analysis_data, choices)

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–∞–±–ª–∏—Ü
    io_rows = _build_io_registry(
        analysis_data.external_inputs,
        analysis_data.final_outputs,
        analysis_data.output_to_operation,
        analysis_data.input_to_operations
    )
    
    critical_ops = {c.operation for c in analysis_data.analysis.critical_points}
    op_rows = _build_op_registry(operations, analysis_data.input_to_operations, critical_ops)

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    available_cols = {
        'group': '–ì—Ä—É–ø–ø–∞' in available_columns,
        'owner': '–í–ª–∞–¥–µ–ª–µ—Ü' in available_columns,
        'detailed_desc': '–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏' in available_columns
    }

    # –°–±–æ—Ä–∫–∞ Markdown –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    md_parts = [
        f"# –î–∏–∞–≥—Ä–∞–º–º–∞ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–∞\n\n",
        f"## –í–∏–∑—É–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞\n\n",
        mermaid_code,
        f"\n\n## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è\n\n",
        f"### üìä –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–µ—Ä—Å–∏—è\n\n",
        f"–î–ª—è –±–æ–ª–µ–µ —É–¥–æ–±–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º—ã –¥–æ—Å—Ç—É–ø–Ω–∞ [–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–µ—Ä—Å–∏—è]({output_base}_vis.html).\n\n",
        f"**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π –≤–µ—Ä—Å–∏–∏:**\n",
        f"- üîç –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø–∞–Ω–æ—Ä–∞–º–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
        f"- üéØ –ü–æ–∏—Å–∫ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n", 
        f"- üìä –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞\n",
        f"- üñ±Ô∏è  –ü—Ä–æ—Å—Ç–æ–µ –ø–µ—Ä–µ—Ç–∞—Å–∫–∏–≤–∞–Ω–∏–µ —É–∑–ª–æ–≤\n\n",
        f"## –ê–Ω–∞–ª–∏–∑ —É–∑–ª–æ–≤ —Å–ª–∏—è–Ω–∏—è, —Ä–∞–∑–≤–µ—Ç–≤–ª–µ–Ω–∏—è –∏ —Å—É–ø–µ—Ä-–∫—Ä–∏—Ç–∏—á–Ω—ã—Ö —Ç–æ—á–µ–∫\n\n",
        f"### –°—É–ø–µ—Ä-–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (–æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ ‚â• "
        f"{choices.critical_min_inputs} –≤—Ö–æ–¥–æ–≤ –∏ –≤—ã—Ö–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ‚â• {choices.critical_min_reuse} —Ä–∞–∑):\n",
    ]
    
    if analysis_data.analysis.critical_points:
        for cp in sorted(analysis_data.analysis.critical_points, key=lambda x: (x.inputs_count, x.output_reuse), reverse=True):
            md_parts.append(f"- **{cp.operation}**: {cp.inputs_count} –≤—Ö–æ–¥–æ–≤, –≤—ã—Ö–æ–¥ –∏–¥—ë—Ç –≤ {cp.output_reuse} –æ–ø–µ—Ä–∞—Ü–∏–π\n")
    else:
        md_parts.append("- –¢–∞–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –Ω–µ—Ç\n")

    md_parts.extend([
        "\n### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–æ—á–∫–∏ —Å–ª–∏—è–Ω–∏—è:\n",
    ])
    if analysis_data.analysis.merge_points:
        for point in sorted(analysis_data.analysis.merge_points, key=lambda x: x.input_count, reverse=True):
            md_parts.append(f"- **{point.operation}**: {point.input_count} –≤—Ö–æ–¥–æ–≤\n")
    else:
        md_parts.append("- –ù–µ—Ç —Ç–æ—á–µ–∫ —Å–ª–∏—è–Ω–∏—è\n")

    md_parts.extend([
        "\n### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–æ—á–∫–∏ —Ä–∞–∑–≤–µ—Ç–≤–ª–µ–Ω–∏—è:\n",
    ])
    if analysis_data.analysis.split_points:
        for point in sorted(analysis_data.analysis.split_points, key=lambda x: x.target_count, reverse=True):
            md_parts.append(f"- **{point.output}** (–∏–∑ {point.source_operation}): –∏–¥—ë—Ç –≤ {point.target_count} –æ–ø–µ—Ä–∞—Ü–∏–π\n")
    else:
        md_parts.append("- –ù–µ—Ç —Ç–æ—á–µ–∫ —Ä–∞–∑–≤–µ—Ç–≤–ª–µ–Ω–∏—è\n")

    md_parts.extend([
        "\n## –†–µ–µ—Å—Ç—Ä –≤—Ö–æ–¥–æ–≤/–≤—ã—Ö–æ–¥–æ–≤\n\n",
        create_markdown_table(["–í—Ö–æ–¥/–í—ã—Ö–æ–¥", "–ò—Å—Ö–æ–¥–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è", "–ü–æ—Å–ª–µ–¥—É—é—â–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏"], io_rows),
        "\n\n## –†–µ–µ—Å—Ç—Ä –æ–ø–µ—Ä–∞—Ü–∏–π\n\n",
    ])

    table_headers = ["–û–ø–µ—Ä–∞—Ü–∏—è"]
    if available_cols['group']:
        table_headers.append("–ì—Ä—É–ø–ø–∞")
    if available_cols['owner']:
        table_headers.append("–í–ª–∞–¥–µ–ª–µ—Ü")
    table_headers.extend(["–í—Ö–æ–¥—ã", "–í—ã—Ö–æ–¥", "–¢–∏–ø —É–∑–ª–∞"])
    if available_cols['detailed_desc']:
        table_headers.append("–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ")
    md_parts.append(create_markdown_table(table_headers, op_rows))

    md_parts.extend([
        f"\n\n## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞\n\n",
        f"- **–í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π**: {analysis_data.analysis.operations_count}\n",
    ])
    if choices.subgroup_column and not choices.no_grouping:
        md_parts.append(f"- **{choices.subgroup_column} –¥–ª—è –¥–∏–∞–≥—Ä–∞–º–º—ã**: {analysis_data.analysis.subgroups_count}\n")
    if available_cols['group'] and choices.subgroup_column != '–ì—Ä—É–ø–ø–∞':
        md_parts.append(f"- **–ì—Ä—É–ø–ø—ã –≤ –¥–∞–Ω–Ω—ã—Ö**: {analysis_data.analysis.groups_count}\n")
    if available_cols['owner'] and choices.subgroup_column != '–í–ª–∞–¥–µ–ª–µ—Ü':
        md_parts.append(f"- **–í–ª–∞–¥–µ–ª—å—Ü—ã –≤ –¥–∞–Ω–Ω—ã—Ö**: {analysis_data.analysis.owners_count}\n")

    md_parts.extend([
        f"- **–í–Ω–µ—à–Ω–∏–µ –≤—Ö–æ–¥—ã**: {len(analysis_data.analysis.external_inputs)}\n",
        f"- **–ö–æ–Ω–µ—á–Ω—ã–µ –≤—ã—Ö–æ–¥—ã**: {len(analysis_data.analysis.final_outputs)}\n",
        f"- **–û–ø–µ—Ä–∞—Ü–∏–π —Å–ª–∏—è–Ω–∏—è**: {len(analysis_data.analysis.merge_points)}\n",
        f"- **–û–ø–µ—Ä–∞—Ü–∏–π —Ä–∞–∑–≤–µ—Ç–≤–ª–µ–Ω–∏—è**: {len(analysis_data.analysis.split_points)}\n",
        f"- **–°—É–ø–µ—Ä-–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π**: {len(analysis_data.analysis.critical_points)}\n",
        f"\n\n## –õ–µ–≥–µ–Ω–¥–∞\n\n",
        f"- **–ñ–µ–ª—Ç—ã–µ –æ–≤–∞–ª—ã** ‚Äì –≤–Ω–µ—à–Ω–∏–µ –≤—Ö–æ–¥—ã\n",
        f"- **–ö—Ä–∞—Å–Ω—ã–µ –æ–≤–∞–ª—ã** ‚Äì –∫–æ–Ω–µ—á–Ω—ã–µ –≤—ã—Ö–æ–¥—ã\n",
        f"- **–û—Ä–∞–Ω–∂–µ–≤—ã–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏** ‚Äì –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å–ª–∏—è–Ω–∏—è\n",
        f"- **–§–∏–æ–ª–µ—Ç–æ–≤—ã–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏** ‚Äì –æ–ø–µ—Ä–∞—Ü–∏–∏ —Ä–∞–∑–≤–µ—Ç–≤–ª–µ–Ω–∏—è\n",
        f"- **–ü—É–ª—å—Å–∏—Ä—É—é—â–∏–µ –∫—Ä–∞—Å–Ω—ã–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏** ‚Äì —Å—É–ø–µ—Ä-–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
        f"- **–û–±—ã—á–Ω—ã–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏** ‚Äì —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
    ])
    if choices.subgroup_column and not choices.no_grouping:
        md_parts.append(f"- **–ì—Ä—É–ø–ø—ã –Ω–∞ –¥–∏–∞–≥—Ä–∞–º–º–µ** ‚Äì –∑–æ–Ω—ã –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ {choices.subgroup_column.lower()}\n")
    if choices.show_detailed:
        md_parts.append(f"- **–¢–µ–∫—Å—Ç —É–∑–ª–æ–≤** ‚Äì —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–π\n")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    output_file.write_text("".join(md_parts), encoding=ENCODING)

    print(f"\n" + "="*60)
    print("‚úì MARKDOWN-–î–ò–ê–ì–†–ê–ú–ú–ê –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù–ê!")
    print("="*60)
    print(f"–§–∞–π–ª: {output_file}")
    print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {analysis_data.analysis.operations_count} –æ–ø–µ—Ä–∞—Ü–∏–π")
    
    return output_file